{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import lightgbm as lgb\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from joblib import load, dump\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from utils.features_ents import feature_ents\n",
    "from utils.ner import ner\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.383 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "9it [00:02,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save features... \n",
      "Training lgb model....\n",
      "[1]\tvalid_0's xentropy: 0.0345824\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's xentropy: 0.0351084\n",
      "[3]\tvalid_0's xentropy: 0.0356076\n",
      "[4]\tvalid_0's xentropy: 0.0360813\n",
      "[5]\tvalid_0's xentropy: 0.0365295\n",
      "[6]\tvalid_0's xentropy: 0.0371864\n",
      "[7]\tvalid_0's xentropy: 0.0378312\n",
      "[8]\tvalid_0's xentropy: 0.0384247\n",
      "[9]\tvalid_0's xentropy: 0.0389891\n",
      "[10]\tvalid_0's xentropy: 0.0395244\n",
      "[11]\tvalid_0's xentropy: 0.0397566\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's xentropy: 0.0345824\n",
      "Save model to model1.joblib\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "class Train():\n",
    "    def __init__(self):\n",
    "        self.train_data_path = \"data/coreEntityEmotion_train.txt\"\n",
    "\n",
    "    def model_lgb(self, X, Y, process_num):\n",
    "            # create dataset for lightgbm\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(X, Y, test_size=0.1, random_state=0)   # 分训练集和验证集    \n",
    "        lgb_train = lgb.Dataset(train_x, train_y)\n",
    "        lgb_eval = lgb.Dataset(valid_x, valid_y, reference=lgb_train)\n",
    "\n",
    "        # specify your configurations as a dict\n",
    "        params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'cross_entropy'},\n",
    "        'num_leaves': 31,\n",
    "        'max_depth' : 3,\n",
    "        'learning_rate': 0.1,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'seed' : 0\n",
    "        }\n",
    "        # train\n",
    "        print(\"Training lgb model....\")\n",
    "        gbm = lgb.train(params,lgb_train,num_boost_round=100,valid_sets=lgb_eval,early_stopping_rounds=10)\n",
    "        print(\"Save model to \"+process_num+\".joblib\")\n",
    "        dump(gbm, \"models/\"+process_num+\".joblib\")\n",
    "    \n",
    "    def train_ents(self):\n",
    "        train_data = open(self.train_data_path)\n",
    "        fea_ents = feature_ents()\n",
    "        ners = []\n",
    "        X = []\n",
    "        Y = []\n",
    "        count = 0\n",
    "        for news in tqdm(train_data):\n",
    "            count += 1\n",
    "            if(count == 10):  #测试能否跑通，测试完去掉\n",
    "                break\n",
    "            news = json.loads(news)\n",
    "            X_data = fea_ents.combine_features(news)\n",
    "            Y_data = [x['entity'] for x in news['coreEntityEmotions']]\n",
    "            for x in X_data:\n",
    "                if x[0][0] in Y_data:\n",
    "                    Y.append(1)\n",
    "                else:\n",
    "                    Y.append(0)\n",
    "                X.append(x[1])\n",
    "            if count == 28000:\n",
    "                print(\"Save features for holdout... \")\n",
    "                dump(X, \"features/holdout_x1.joblib\")\n",
    "                dump(Y, \"features/holdout_y1.joblib\")\n",
    "        print(\"Save features... \")\n",
    "        dump(X, \"features/x1.joblib\")\n",
    "        dump(Y, \"features/y1.joblib\")\n",
    "        self.model_lgb(X, Y, \"model1\")\n",
    "        print(\"done!\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train = Train()\n",
    "    train.train_ents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
